{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/tyfei/evoModel/utils.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib \n",
    "import modules\n",
    "from esm.models.esm3 import ESM3\n",
    "from esm.sdk.api import ESMProtein, GenerationConfig\n",
    "import pytorch_lightning as L\n",
    "import json \n",
    "import utils\n",
    "import torch\n",
    "import pickle\n",
    "import VirusDataset\n",
    "import os\n",
    "import trainUtils\n",
    "importlib.reload(trainUtils)\n",
    "importlib.reload(modules) \n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers', 'hparams_name', 'hyper_parameters'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"/data/tyfei/datasets/covid/teststage2NSP5_lr_backbone_.pkl\", \"wb\") as f:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "class a(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs) \n",
    "        \n",
    "        self.tt = torch.randn(5)\n",
    "        self.register_buffer(\"qq\", self.tt) \n",
    "        \n",
    "b = a().cuda(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.4388, -0.3029, -1.2500, -0.0645, -0.0296], device='cuda:5')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(b, \"qq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn((4, 5))\n",
    "b = torch.tensor([1,3,2,0]) \n",
    "c = torch.nn.CrossEntropyLoss()\n",
    "c(a, b).shape\n",
    "# torch.sum(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"/home/tyfei/evoModel/checkpoints/CrossGene\", \"config.json\"), \"r\") as f:\n",
    "    configs = json.load(f)\n",
    "# json_formatted_str = json.dumps(configs, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules \n",
    "importlib.reload(modules)\n",
    "t = modules.CrossGeneModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_model = trainUtils.loadPretrainModel(configs)\n",
    "model = trainUtils.buildModel(configs, pretrain_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 3, 5], [4, 2]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_test_split([1,2,3,4,5], test_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"/data/tyfei/datasets/covid/teststage2_1000.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = trainUtils.loadDataset(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [{'NSP5': tensor([[-6.8268e-01, -7.8118e-01, -2.8831e-01,  3.4511e-01,  2.2861e+00,\n",
      "         -4.4230e-01, -4.0033e+00,  9.9497e+00, -1.8650e+00,  5.2941e+01,\n",
      "         -9.4199e-01, -1.0918e+00, -2.3771e+00, -8.4205e-01, -7.0225e-01,\n",
      "         -3.7638e-01,  9.9604e-01,  5.5504e-01,  7.9534e-02, -5.8820e-01,\n",
      "          3.4026e-01, -1.5439e-02, -6.9093e-01,  2.5183e-01,  3.4380e+01,\n",
      "          3.1016e+01,  1.0338e-01, -5.0231e-01, -9.4218e-01,  4.3444e-01,\n",
      "         -3.4038e-01, -2.2222e+00, -3.4882e-01, -6.7139e-01, -1.4452e+00,\n",
      "         -5.6040e-01,  1.2748e+00,  1.4026e-01, -2.2222e+00,  1.2634e+00,\n",
      "          1.4212e-02, -1.6183e-01, -1.3583e+00, -1.1059e+00, -2.1534e-01,\n",
      "         -3.0375e-01, -7.2954e-01,  5.0665e-01,  3.5001e-01, -3.1550e+00,\n",
      "         -6.6769e-01, -8.5127e-01,  1.6604e+00, -2.3222e-01, -7.0217e-01,\n",
      "         -1.6999e+00,  6.5728e-01, -2.5063e-01, -9.5847e-01,  8.1072e-02,\n",
      "         -3.0711e-01,  3.3391e-01,  1.6599e-01, -1.9125e+00,  1.8410e+00,\n",
      "         -8.7256e-01,  6.3883e-01, -2.7751e-01, -2.7710e-01,  8.4906e-01,\n",
      "          2.1253e+00,  1.1105e+00,  8.9995e-01,  2.5435e-01, -1.7420e+00,\n",
      "         -7.7190e-01,  4.4270e-01,  1.8836e+00, -1.0468e+00, -2.3995e+00,\n",
      "          3.7490e-01, -7.0235e-02,  1.2358e+00, -8.3689e-01,  5.7534e-01,\n",
      "         -1.0102e+00, -5.1299e-01, -2.5238e-01, -2.1226e-01,  6.7681e-01,\n",
      "          1.3638e+00, -8.3717e-01,  7.0773e-02,  9.1665e-01, -8.1275e-01,\n",
      "         -2.1467e+00, -4.5149e-01,  1.9201e+00, -4.6459e-01, -4.7926e-02,\n",
      "          7.2837e-01, -2.8887e+00, -3.7578e-01, -1.5735e+00, -4.3090e-01,\n",
      "         -2.9689e-01,  1.2843e+00,  1.2569e-02,  1.0983e+00,  3.3592e-01,\n",
      "         -3.3664e-01, -1.1267e+00,  2.0003e+00,  6.5556e-01,  2.1641e+00,\n",
      "          1.2619e+00,  1.0806e+00, -1.1719e+00,  2.2400e-01,  9.5399e-01,\n",
      "         -1.0044e+00,  7.7196e-02,  8.3546e-01, -1.6518e+00, -2.3310e-01,\n",
      "         -5.3104e-02, -2.0700e+00,  6.7991e-01, -7.7736e-01,  1.5825e+00,\n",
      "          2.6965e+00,  6.1720e-01, -1.1089e+00,  1.5934e+00,  7.0918e-01,\n",
      "          2.5017e+00,  4.0037e-01,  6.1416e-01,  1.3240e+00,  9.8919e-01,\n",
      "          6.2156e-01, -1.1346e+00,  9.2516e-01, -1.3345e+00,  4.8316e-01,\n",
      "         -9.0710e-02, -7.4396e-01,  8.5273e-01, -1.6299e+00,  2.2479e+00,\n",
      "         -1.0988e+00, -8.5273e-01, -9.0197e-02, -6.3228e-01, -2.4558e+00,\n",
      "          1.2210e+00, -5.1101e-02,  6.0615e-02,  2.5475e-01, -9.6828e-01,\n",
      "         -1.2107e+00,  5.1558e-02,  6.8231e-01, -2.2140e+00, -5.2921e-01,\n",
      "         -3.1145e-01, -9.4502e-01, -1.3872e+00,  6.4705e-01,  6.6483e-01,\n",
      "          1.1058e-01,  1.0795e+00, -6.4832e-01,  3.6724e-01, -1.1929e+00,\n",
      "         -6.8199e-02, -3.7927e-02,  8.6140e-01, -6.2971e-01, -9.5078e-01,\n",
      "          1.8934e+00, -1.4240e+00, -1.2771e+00,  9.0003e-01,  1.7373e-01,\n",
      "         -1.7104e-01, -6.0286e-01,  4.0982e-01, -3.4965e-01,  9.9531e-01,\n",
      "          1.2272e+00, -2.0594e+00, -9.8451e-01,  6.9530e-01,  1.7607e+00,\n",
      "         -1.6238e+00,  5.4346e+01, -1.5491e+01,  9.0488e-02, -2.8035e-02,\n",
      "         -2.2594e-01,  1.2238e+00,  7.7611e-01,  1.3238e+00, -9.5717e-01,\n",
      "          2.2165e-01, -1.3392e+00, -2.9943e+00,  1.6117e+00,  7.0433e-01,\n",
      "          2.9127e-01, -4.2990e-01,  1.7633e+00, -4.6114e-01, -2.2370e-01,\n",
      "         -5.9669e-01,  2.9232e-02,  4.9832e-01,  1.4556e+00, -1.2835e+00,\n",
      "          1.8860e-02, -9.0605e-01, -1.0225e+00, -5.2548e-01,  5.1709e-01,\n",
      "          4.9564e-01,  8.4000e-01, -8.0261e-01, -1.5900e-02, -5.4624e-01,\n",
      "          1.4500e+00, -1.3096e-01, -7.8288e-01,  6.1418e-02, -2.2174e-01,\n",
      "          4.7192e-02, -3.6841e-01, -1.1618e+00,  2.6496e+00, -4.1436e-01,\n",
      "         -5.3669e+00, -4.9631e+01, -3.2927e-01, -2.1696e+00, -7.2670e-01,\n",
      "         -6.1975e-01,  1.1821e+00,  4.3833e-01, -4.6833e-01, -2.3272e-01,\n",
      "         -8.4237e-01, -6.7292e-01, -7.5220e-01, -7.8671e-01, -1.7007e+00,\n",
      "          1.0391e+00]]), 'E': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'S': tensor([[-5.8103e-02, -6.2397e-01, -3.1427e-01,  6.9007e-01, -6.8726e-01,\n",
      "          2.6997e-01,  7.6722e-01, -2.1925e+00, -3.8423e+01, -1.9715e+00,\n",
      "          2.0232e-01,  5.4811e-01,  8.0416e-03,  1.3242e+00, -1.3873e+00,\n",
      "          4.0157e-01,  2.3943e-01, -2.2910e-01, -4.1534e-01,  7.2407e-02,\n",
      "          3.2087e-01,  4.1246e-01, -6.4724e-01,  1.9282e-01,  3.2304e+01,\n",
      "         -3.8210e+01, -1.3699e-01,  4.2498e-01,  3.7121e-01, -4.8019e-01,\n",
      "          8.3199e-01, -3.8770e-01,  1.1888e-01,  9.6986e-01,  4.3799e-01,\n",
      "          1.0680e+00,  3.7396e-01,  1.7554e-01,  6.6262e-02, -5.6363e-01,\n",
      "         -2.9293e-01,  1.9924e-01, -2.9839e-01,  7.5316e-02,  1.0857e-01,\n",
      "          1.1704e-02,  7.5143e-01,  1.4342e+00,  1.1974e+00,  3.4142e-01,\n",
      "          3.4036e-01,  5.7689e-01,  1.2826e-01,  7.5565e-01,  1.0067e+00,\n",
      "          6.4358e-01, -1.3416e-01, -1.0922e-01,  2.1143e-01, -5.2161e-01,\n",
      "          1.4291e-01, -3.4486e-01, -4.1166e-01,  4.0277e-01, -7.8460e-02,\n",
      "         -2.1519e-01, -4.6413e-01, -1.4349e+00,  2.1186e-01, -3.7756e-01,\n",
      "         -2.2489e-01,  1.0566e-01, -3.3667e-01, -5.4563e-02,  6.0152e-01,\n",
      "         -4.1835e-01,  5.0824e-01,  4.3433e-01, -6.2613e-01,  5.9962e-02,\n",
      "         -6.3427e-02,  3.4695e-01, -1.2894e-01, -5.4380e-01, -8.2659e-01,\n",
      "          4.1606e-01,  2.4675e-01,  9.1849e-02, -1.5840e-01, -1.0771e-01,\n",
      "          5.9359e-01,  3.8477e-01,  5.8745e-01,  5.9871e-01, -1.6658e+00,\n",
      "         -8.3114e-01, -1.7031e-01,  5.5869e-01, -3.0008e-01,  2.4634e-01,\n",
      "          7.0498e-01,  5.3694e-01, -5.3508e-01, -6.0159e-01, -5.2515e-01,\n",
      "          1.1339e-01, -1.7588e-01,  9.8344e-01, -9.8990e-01, -1.0962e-01,\n",
      "          3.1515e-01, -3.4713e-01,  2.8316e-01,  4.6848e-01,  8.1563e-01,\n",
      "         -7.4418e-01,  8.9058e-01,  1.0644e+00, -3.6785e-01,  8.7700e-02,\n",
      "         -1.5873e-01, -2.4507e-01,  8.5372e-02,  1.2632e-01,  1.5639e-01,\n",
      "          3.7088e-01, -6.6416e-01,  1.7170e+00,  2.1257e-01,  1.3190e-01,\n",
      "         -2.6887e-02, -1.6622e-01,  9.7097e-02, -3.7453e-01,  1.1787e+00,\n",
      "          1.0823e+00, -1.1536e-02,  1.1612e-01, -5.8172e-01, -3.0398e-01,\n",
      "         -1.1691e+00,  2.8882e-02,  1.4137e-01,  8.9029e-01, -1.2777e-01,\n",
      "          4.0492e-01, -1.4042e-01,  9.8257e-01, -1.0374e+00, -1.1636e+00,\n",
      "          1.7129e-01,  1.9965e-01, -2.1101e-01, -2.1758e-01, -3.3281e-01,\n",
      "          2.2939e-01, -2.2841e-01,  7.4006e-01, -5.8902e-02,  5.7930e-02,\n",
      "          6.0721e-03, -5.3339e-01, -3.8795e-01, -1.5171e-01,  8.3674e-01,\n",
      "          1.7401e-01,  4.1147e-01,  1.6225e-01,  2.7467e-01, -7.4511e-02,\n",
      "         -1.8714e-02, -5.5456e-01, -9.2777e-02,  3.0637e-01,  3.2397e-01,\n",
      "          6.1364e-01, -9.9390e-02,  2.1851e-01,  2.4259e-01,  7.4617e-01,\n",
      "         -3.8986e-01,  9.5899e-01, -7.1876e-01, -1.3614e+00, -2.0727e-01,\n",
      "          3.9199e-01, -1.4503e-01,  3.4604e-04, -1.4865e-01, -2.9758e-01,\n",
      "          3.5231e-01,  4.0631e-01, -1.1264e+00, -7.2773e-01,  2.0617e-01,\n",
      "         -1.2301e-01,  1.8890e+01, -4.8895e+01, -7.4790e-01,  1.4379e+00,\n",
      "         -4.3537e-01,  1.1950e-01,  1.7560e-01, -2.1263e-01, -5.2542e-01,\n",
      "         -2.9686e-02, -3.7173e-01, -2.7555e-01,  4.3437e-01,  5.9806e-01,\n",
      "         -8.7620e-01,  9.8991e-01, -4.6914e-01,  2.5187e-01,  4.9735e-01,\n",
      "          5.6594e-01,  2.3996e-01, -2.0946e-01,  4.1445e-02, -9.7275e-01,\n",
      "          3.2612e-01,  2.6362e-02, -4.9850e-01,  1.9846e-01,  1.3540e-01,\n",
      "         -5.6445e-01, -2.6098e-01, -6.9766e-01, -8.1520e-01,  1.0282e-01,\n",
      "          4.5228e-01, -6.9802e-01, -3.3931e-02, -1.6075e-01, -3.1075e-01,\n",
      "          1.7067e-01, -3.3275e-01,  5.0354e-01, -1.2868e+00, -1.1503e+00,\n",
      "         -4.7864e+01,  2.1681e+01, -4.9029e-02,  7.4146e-01,  2.8078e-01,\n",
      "          4.8135e-01, -1.4389e-01, -3.4368e-02,  1.6492e-01,  2.2247e-01,\n",
      "          1.1517e-01, -5.6197e-01, -7.7802e-02,  3.4801e-01, -7.3631e-01,\n",
      "          1.3699e+00]]), 'ori_NSP5': tensor([[-6.8268e-01, -7.8118e-01, -2.8831e-01,  3.4511e-01,  2.2861e+00,\n",
      "         -4.4230e-01, -4.0033e+00,  9.9497e+00, -1.8650e+00,  5.2941e+01,\n",
      "         -9.4199e-01, -1.0918e+00, -2.3771e+00, -8.4205e-01, -7.0225e-01,\n",
      "         -3.7638e-01,  9.9604e-01,  5.5504e-01,  7.9534e-02, -5.8820e-01,\n",
      "          3.4026e-01, -1.5439e-02, -6.9093e-01,  2.5183e-01,  3.4380e+01,\n",
      "          3.1016e+01,  1.0338e-01, -5.0231e-01, -9.4218e-01,  4.3444e-01,\n",
      "         -3.4038e-01, -2.2222e+00, -3.4882e-01, -6.7139e-01, -1.4452e+00,\n",
      "         -5.6040e-01,  1.2748e+00,  1.4026e-01, -2.2222e+00,  1.2634e+00,\n",
      "          1.4212e-02, -1.6183e-01, -1.3583e+00, -1.1059e+00, -2.1534e-01,\n",
      "         -3.0375e-01, -7.2954e-01,  5.0665e-01,  3.5001e-01, -3.1550e+00,\n",
      "         -6.6769e-01, -8.5127e-01,  1.6604e+00, -2.3222e-01, -7.0217e-01,\n",
      "         -1.6999e+00,  6.5728e-01, -2.5063e-01, -9.5847e-01,  8.1072e-02,\n",
      "         -3.0711e-01,  3.3391e-01,  1.6599e-01, -1.9125e+00,  1.8410e+00,\n",
      "         -8.7256e-01,  6.3883e-01, -2.7751e-01, -2.7710e-01,  8.4906e-01,\n",
      "          2.1253e+00,  1.1105e+00,  8.9995e-01,  2.5435e-01, -1.7420e+00,\n",
      "         -7.7190e-01,  4.4270e-01,  1.8836e+00, -1.0468e+00, -2.3995e+00,\n",
      "          3.7490e-01, -7.0235e-02,  1.2358e+00, -8.3689e-01,  5.7534e-01,\n",
      "         -1.0102e+00, -5.1299e-01, -2.5238e-01, -2.1226e-01,  6.7681e-01,\n",
      "          1.3638e+00, -8.3717e-01,  7.0773e-02,  9.1665e-01, -8.1275e-01,\n",
      "         -2.1467e+00, -4.5149e-01,  1.9201e+00, -4.6459e-01, -4.7926e-02,\n",
      "          7.2837e-01, -2.8887e+00, -3.7578e-01, -1.5735e+00, -4.3090e-01,\n",
      "         -2.9689e-01,  1.2843e+00,  1.2569e-02,  1.0983e+00,  3.3592e-01,\n",
      "         -3.3664e-01, -1.1267e+00,  2.0003e+00,  6.5556e-01,  2.1641e+00,\n",
      "          1.2619e+00,  1.0806e+00, -1.1719e+00,  2.2400e-01,  9.5399e-01,\n",
      "         -1.0044e+00,  7.7196e-02,  8.3546e-01, -1.6518e+00, -2.3310e-01,\n",
      "         -5.3104e-02, -2.0700e+00,  6.7991e-01, -7.7736e-01,  1.5825e+00,\n",
      "          2.6965e+00,  6.1720e-01, -1.1089e+00,  1.5934e+00,  7.0918e-01,\n",
      "          2.5017e+00,  4.0037e-01,  6.1416e-01,  1.3240e+00,  9.8919e-01,\n",
      "          6.2156e-01, -1.1346e+00,  9.2516e-01, -1.3345e+00,  4.8316e-01,\n",
      "         -9.0710e-02, -7.4396e-01,  8.5273e-01, -1.6299e+00,  2.2479e+00,\n",
      "         -1.0988e+00, -8.5273e-01, -9.0197e-02, -6.3228e-01, -2.4558e+00,\n",
      "          1.2210e+00, -5.1101e-02,  6.0615e-02,  2.5475e-01, -9.6828e-01,\n",
      "         -1.2107e+00,  5.1558e-02,  6.8231e-01, -2.2140e+00, -5.2921e-01,\n",
      "         -3.1145e-01, -9.4502e-01, -1.3872e+00,  6.4705e-01,  6.6483e-01,\n",
      "          1.1058e-01,  1.0795e+00, -6.4832e-01,  3.6724e-01, -1.1929e+00,\n",
      "         -6.8199e-02, -3.7927e-02,  8.6140e-01, -6.2971e-01, -9.5078e-01,\n",
      "          1.8934e+00, -1.4240e+00, -1.2771e+00,  9.0003e-01,  1.7373e-01,\n",
      "         -1.7104e-01, -6.0286e-01,  4.0982e-01, -3.4965e-01,  9.9531e-01,\n",
      "          1.2272e+00, -2.0594e+00, -9.8451e-01,  6.9530e-01,  1.7607e+00,\n",
      "         -1.6238e+00,  5.4346e+01, -1.5491e+01,  9.0488e-02, -2.8035e-02,\n",
      "         -2.2594e-01,  1.2238e+00,  7.7611e-01,  1.3238e+00, -9.5717e-01,\n",
      "          2.2165e-01, -1.3392e+00, -2.9943e+00,  1.6117e+00,  7.0433e-01,\n",
      "          2.9127e-01, -4.2990e-01,  1.7633e+00, -4.6114e-01, -2.2370e-01,\n",
      "         -5.9669e-01,  2.9232e-02,  4.9832e-01,  1.4556e+00, -1.2835e+00,\n",
      "          1.8860e-02, -9.0605e-01, -1.0225e+00, -5.2548e-01,  5.1709e-01,\n",
      "          4.9564e-01,  8.4000e-01, -8.0261e-01, -1.5900e-02, -5.4624e-01,\n",
      "          1.4500e+00, -1.3096e-01, -7.8288e-01,  6.1418e-02, -2.2174e-01,\n",
      "          4.7192e-02, -3.6841e-01, -1.1618e+00,  2.6496e+00, -4.1436e-01,\n",
      "         -5.3669e+00, -4.9631e+01, -3.2927e-01, -2.1696e+00, -7.2670e-01,\n",
      "         -6.1975e-01,  1.1821e+00,  4.3833e-01, -4.6833e-01, -2.3272e-01,\n",
      "         -8.4237e-01, -6.7292e-01, -7.5220e-01, -7.8671e-01, -1.7007e+00,\n",
      "          1.0391e+00]]), 'ori_E': tensor([[ 6.0916e-01,  1.4854e+00, -1.4125e+00,  2.2441e+00,  3.7676e+00,\n",
      "          1.5396e+00,  1.1101e+01, -2.9598e+01,  1.9934e+01,  8.3451e+00,\n",
      "          2.4724e-01,  7.9118e-02,  2.7553e+00, -1.1231e+00,  1.7543e+00,\n",
      "         -1.3116e+00,  3.0956e+00,  9.3569e-01,  2.3288e-01,  2.9500e+00,\n",
      "         -2.7160e-01,  1.4673e+00, -8.8871e-01,  1.4430e+00,  1.2244e+01,\n",
      "         -9.0748e+00,  5.4097e-01,  6.1872e-03, -2.6311e-01, -1.2455e+00,\n",
      "          1.7041e+00,  1.6617e-01, -4.8193e-01, -4.1589e-01,  1.8427e-01,\n",
      "          1.3777e+00,  1.1030e+00,  2.4516e+00, -2.6454e+00,  1.5801e+00,\n",
      "         -2.0716e+00,  5.5731e-02, -9.8925e-01,  6.8975e-01, -3.2185e-01,\n",
      "         -3.0334e-01,  4.6855e-01,  1.2868e+00, -3.6742e+00, -1.4774e-01,\n",
      "          2.1200e+00, -5.6248e-01,  1.0151e+00,  4.6267e-01, -6.7655e+00,\n",
      "          7.9669e+00, -3.6495e+00,  1.5068e+00,  2.1650e-01, -2.7015e+00,\n",
      "          2.1806e-01, -3.8602e-01, -2.3201e+00,  3.6284e+00,  2.2772e+00,\n",
      "          1.3118e+00, -1.1838e-01,  2.2118e+00, -3.7001e+00, -1.3000e+00,\n",
      "          2.3672e+00,  1.4697e+00, -4.3154e+00, -5.4229e-01, -4.2402e-01,\n",
      "          2.2924e+00, -4.0889e+00, -2.2722e+00, -7.1544e-01,  1.7770e+00,\n",
      "          2.3737e+00,  6.9329e-01, -3.0852e+00,  1.6057e-01,  5.0493e+00,\n",
      "         -2.9826e-01, -3.0159e+00,  1.3258e+00, -3.3791e+00, -3.1770e+00,\n",
      "         -1.7742e+00,  2.1336e+00,  7.7542e-01, -4.7854e-01, -1.5600e+00,\n",
      "          5.1377e-01,  6.4027e-01,  1.5528e-01, -4.6094e-02, -1.9474e+00,\n",
      "          5.7410e-01,  1.3588e+00,  6.7285e-01, -7.0780e-01, -1.9503e+00,\n",
      "         -4.8011e-02, -1.4477e+00, -1.6047e+00, -1.5794e+00, -2.0342e+00,\n",
      "         -1.9347e+00,  3.4241e-01, -6.6700e-01,  9.5455e-01,  1.0105e+00,\n",
      "         -2.0220e+00, -3.1345e+00,  1.9430e+00, -1.4055e+00,  1.4346e+00,\n",
      "         -6.8891e-01, -2.6954e+00, -2.8605e+00,  2.8860e+00, -1.8533e+00,\n",
      "          1.5979e+00,  3.6517e-02, -9.3978e-01, -6.3473e-01,  3.9875e+00,\n",
      "         -2.4719e-01,  4.7450e-01, -1.4795e-01, -3.6211e+00, -1.1746e+00,\n",
      "          7.0608e-01, -5.2568e-01,  7.4690e-02, -2.4193e-02,  1.4402e+00,\n",
      "         -7.6401e-01,  8.0642e-01, -1.6412e+00,  9.6295e-01,  1.9275e+00,\n",
      "          3.3236e+00,  1.0530e+00, -1.4306e+00,  1.3485e+00, -1.3578e+00,\n",
      "         -8.0171e-01, -6.0030e-01,  2.1090e-01,  1.0386e+00,  3.7311e-01,\n",
      "         -1.6911e+00, -1.2275e+00, -1.6062e+00, -1.9865e+00,  1.4301e+00,\n",
      "         -2.3681e+00, -6.7425e-01, -6.1606e-01,  4.7009e-01,  3.1059e-01,\n",
      "          1.5122e+00,  1.4935e-01, -1.4370e+00, -1.3036e+00, -9.0344e-01,\n",
      "         -3.0616e+00, -2.6793e+00, -2.9308e+00, -1.2609e+00, -1.9843e-01,\n",
      "          1.9782e+00,  2.1469e-01,  2.2314e+00,  6.2013e-01,  2.1543e-01,\n",
      "          3.5568e+00,  1.0360e+00, -2.3467e-02,  2.4274e+00,  2.3978e-02,\n",
      "          1.9769e+00, -1.4514e+00,  1.8829e-01, -2.3631e+00,  3.0405e-01,\n",
      "         -1.0909e+00,  1.5420e+00,  2.2304e+00, -1.3001e+00,  1.6429e+00,\n",
      "          4.7628e-01,  5.3881e+00, -3.8463e+01,  7.4217e-01, -1.2608e+00,\n",
      "         -3.1063e+00,  6.7350e-01, -4.2654e+00, -1.9836e+00,  1.5769e+00,\n",
      "         -2.4965e+00,  7.0794e-01,  1.9665e+00, -1.0148e+00,  6.6399e-01,\n",
      "          2.2860e+00, -2.2235e+00, -1.1806e+00,  1.0574e+00,  1.2873e+00,\n",
      "         -1.0934e+00, -1.6728e+00, -9.7829e-02,  5.6858e-01,  1.3439e+00,\n",
      "          2.9671e-01,  9.8105e-01, -7.6661e-01,  2.8165e-01,  4.7192e-01,\n",
      "          3.8118e+00,  2.7729e+00, -1.2612e+00,  4.7842e+00, -6.0013e-01,\n",
      "          6.7163e-01, -1.7165e-01, -2.0720e+00,  2.2440e+00, -1.3594e+00,\n",
      "         -1.9539e+00,  1.7058e+00, -8.4217e-01, -4.8680e-01, -7.1948e-01,\n",
      "         -1.3094e+01,  3.6079e+01,  2.2595e+00,  7.1304e-01, -2.4393e-01,\n",
      "          2.1659e-01,  1.6911e+00,  2.1900e+00, -7.5232e-01, -1.2787e+00,\n",
      "         -1.8109e+00, -2.4066e+00,  1.9764e+00, -3.6906e-01, -4.5035e+00,\n",
      "         -2.2044e+00]]), 'ori_S': tensor([[-5.8103e-02, -6.2397e-01, -3.1427e-01,  6.9007e-01, -6.8726e-01,\n",
      "          2.6997e-01,  7.6722e-01, -2.1925e+00, -3.8423e+01, -1.9715e+00,\n",
      "          2.0232e-01,  5.4811e-01,  8.0416e-03,  1.3242e+00, -1.3873e+00,\n",
      "          4.0157e-01,  2.3943e-01, -2.2910e-01, -4.1534e-01,  7.2407e-02,\n",
      "          3.2087e-01,  4.1246e-01, -6.4724e-01,  1.9282e-01,  3.2304e+01,\n",
      "         -3.8210e+01, -1.3699e-01,  4.2498e-01,  3.7121e-01, -4.8019e-01,\n",
      "          8.3199e-01, -3.8770e-01,  1.1888e-01,  9.6986e-01,  4.3799e-01,\n",
      "          1.0680e+00,  3.7396e-01,  1.7554e-01,  6.6262e-02, -5.6363e-01,\n",
      "         -2.9293e-01,  1.9924e-01, -2.9839e-01,  7.5316e-02,  1.0857e-01,\n",
      "          1.1704e-02,  7.5143e-01,  1.4342e+00,  1.1974e+00,  3.4142e-01,\n",
      "          3.4036e-01,  5.7689e-01,  1.2826e-01,  7.5565e-01,  1.0067e+00,\n",
      "          6.4358e-01, -1.3416e-01, -1.0922e-01,  2.1143e-01, -5.2161e-01,\n",
      "          1.4291e-01, -3.4486e-01, -4.1166e-01,  4.0277e-01, -7.8460e-02,\n",
      "         -2.1519e-01, -4.6413e-01, -1.4349e+00,  2.1186e-01, -3.7756e-01,\n",
      "         -2.2489e-01,  1.0566e-01, -3.3667e-01, -5.4563e-02,  6.0152e-01,\n",
      "         -4.1835e-01,  5.0824e-01,  4.3433e-01, -6.2613e-01,  5.9962e-02,\n",
      "         -6.3427e-02,  3.4695e-01, -1.2894e-01, -5.4380e-01, -8.2659e-01,\n",
      "          4.1606e-01,  2.4675e-01,  9.1849e-02, -1.5840e-01, -1.0771e-01,\n",
      "          5.9359e-01,  3.8477e-01,  5.8745e-01,  5.9871e-01, -1.6658e+00,\n",
      "         -8.3114e-01, -1.7031e-01,  5.5869e-01, -3.0008e-01,  2.4634e-01,\n",
      "          7.0498e-01,  5.3694e-01, -5.3508e-01, -6.0159e-01, -5.2515e-01,\n",
      "          1.1339e-01, -1.7588e-01,  9.8344e-01, -9.8990e-01, -1.0962e-01,\n",
      "          3.1515e-01, -3.4713e-01,  2.8316e-01,  4.6848e-01,  8.1563e-01,\n",
      "         -7.4418e-01,  8.9058e-01,  1.0644e+00, -3.6785e-01,  8.7700e-02,\n",
      "         -1.5873e-01, -2.4507e-01,  8.5372e-02,  1.2632e-01,  1.5639e-01,\n",
      "          3.7088e-01, -6.6416e-01,  1.7170e+00,  2.1257e-01,  1.3190e-01,\n",
      "         -2.6887e-02, -1.6622e-01,  9.7097e-02, -3.7453e-01,  1.1787e+00,\n",
      "          1.0823e+00, -1.1536e-02,  1.1612e-01, -5.8172e-01, -3.0398e-01,\n",
      "         -1.1691e+00,  2.8882e-02,  1.4137e-01,  8.9029e-01, -1.2777e-01,\n",
      "          4.0492e-01, -1.4042e-01,  9.8257e-01, -1.0374e+00, -1.1636e+00,\n",
      "          1.7129e-01,  1.9965e-01, -2.1101e-01, -2.1758e-01, -3.3281e-01,\n",
      "          2.2939e-01, -2.2841e-01,  7.4006e-01, -5.8902e-02,  5.7930e-02,\n",
      "          6.0721e-03, -5.3339e-01, -3.8795e-01, -1.5171e-01,  8.3674e-01,\n",
      "          1.7401e-01,  4.1147e-01,  1.6225e-01,  2.7467e-01, -7.4511e-02,\n",
      "         -1.8714e-02, -5.5456e-01, -9.2777e-02,  3.0637e-01,  3.2397e-01,\n",
      "          6.1364e-01, -9.9390e-02,  2.1851e-01,  2.4259e-01,  7.4617e-01,\n",
      "         -3.8986e-01,  9.5899e-01, -7.1876e-01, -1.3614e+00, -2.0727e-01,\n",
      "          3.9199e-01, -1.4503e-01,  3.4604e-04, -1.4865e-01, -2.9758e-01,\n",
      "          3.5231e-01,  4.0631e-01, -1.1264e+00, -7.2773e-01,  2.0617e-01,\n",
      "         -1.2301e-01,  1.8890e+01, -4.8895e+01, -7.4790e-01,  1.4379e+00,\n",
      "         -4.3537e-01,  1.1950e-01,  1.7560e-01, -2.1263e-01, -5.2542e-01,\n",
      "         -2.9686e-02, -3.7173e-01, -2.7555e-01,  4.3437e-01,  5.9806e-01,\n",
      "         -8.7620e-01,  9.8991e-01, -4.6914e-01,  2.5187e-01,  4.9735e-01,\n",
      "          5.6594e-01,  2.3996e-01, -2.0946e-01,  4.1445e-02, -9.7275e-01,\n",
      "          3.2612e-01,  2.6362e-02, -4.9850e-01,  1.9846e-01,  1.3540e-01,\n",
      "         -5.6445e-01, -2.6098e-01, -6.9766e-01, -8.1520e-01,  1.0282e-01,\n",
      "          4.5228e-01, -6.9802e-01, -3.3931e-02, -1.6075e-01, -3.1075e-01,\n",
      "          1.7067e-01, -3.3275e-01,  5.0354e-01, -1.2868e+00, -1.1503e+00,\n",
      "         -4.7864e+01,  2.1681e+01, -4.9029e-02,  7.4146e-01,  2.8078e-01,\n",
      "          4.8135e-01, -1.4389e-01, -3.4368e-02,  1.6492e-01,  2.2247e-01,\n",
      "          1.1517e-01, -5.6197e-01, -7.7802e-02,  3.4801e-01, -7.3631e-01,\n",
      "          1.3699e+00]])}, {'NSP5': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1.]]), 'E': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'S': tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1.]])}, tensor([], size=(1, 0), dtype=torch.float64)]\n"
     ]
    }
   ],
   "source": [
    "dl = ds.train_dataloader()\n",
    "for i, j in enumerate(ds.train_dataloader()):\n",
    "    print(i, j)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/core/module.py:447: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(9.9060, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.training_step(j, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = trainUtils.buildTrainer(configs, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn((1, 5))\n",
    "a.float()\n",
    "# a.flatten().shape \n",
    "a.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get train loader\n"
     ]
    }
   ],
   "source": [
    "dl = ds.train_dataloader() \n",
    "for i, j in enumerate(dl):\n",
    "    # print(i, j[0])\n",
    "    if 24 in j[0][\"seq_t\"]:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 1], dtype=torch.int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j[0][\"mask\"][0][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24, 3, 1, 31, 29]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.ds.unlearn_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.stack([torch.rand((6)),torch.rand(6)]).shape\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "\"\"\" checkpoint_callback = ModelCheckpoint(\n",
    "        monitor=\"validate_acc\",  # Replace with your validation metric\n",
    "        mode=\"max\",  # 'min' if the metric should be minimized (e.g., loss), 'max' for maximization (e.g., accuracy)\n",
    "        save_top_k=k,  # Save top k checkpoints based on the monitored metric\n",
    "        save_last=True,  # Save the last checkpoint at the end of training\n",
    "        dirpath=args.path,  # Directory where the checkpoints will be saved\n",
    "        filename=\"{epoch}-{validate_acc:.2f}\",  # Checkpoint file naming pattern\n",
    "    ) \"\"\"\n",
    "\n",
    "\n",
    "trainer = L.Trainer(\n",
    "        # logger=logger,\n",
    "        accelerator=\"gpu\",\n",
    "        # profiler=profiler,\n",
    "        devices=[5],\n",
    "        max_epochs=configs[\"train\"][\"epoch\"],\n",
    "        log_every_n_steps=1,\n",
    "        accumulate_grad_batches=configs[\"train\"][\"accumulate_grad_batches\"],\n",
    "        # callbacks=cbs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seq_t': tensor([[ 0,  8,  6, 18, 10, 15, 20, 32, 18, 14,  8,  6, 15,  7,  9,  6, 23, 20,\n",
       "           7, 16,  7, 11, 23,  6, 11, 11, 11,  4, 17,  6,  4, 22,  4, 13, 13,  7,\n",
       "           7, 19, 32, 14, 10, 32,  7, 12, 23, 11,  8, 32, 13, 20,  4, 17, 14, 32,\n",
       "          19, 32, 32,  4,  4, 32, 32, 15,  8, 17, 21, 17, 18,  4,  7, 16, 32,  6,\n",
       "          17,  7, 16,  4, 10,  7, 12,  6, 32, 32, 20, 32, 17, 23,  7,  4, 15,  4,\n",
       "          32,  7, 13, 11,  5, 17, 14, 15, 11, 14, 15, 19, 15, 18,  7, 10, 12, 16,\n",
       "          14,  6, 16, 11, 18,  8,  7,  4,  5, 23, 19, 17, 32,  8, 32,  8,  6,  7,\n",
       "          19, 16, 23,  5, 20, 10, 21, 17, 18, 11, 12, 15, 32,  8, 18, 32, 17,  6,\n",
       "           8, 32,  6, 32,  7,  6, 18, 17, 12, 13, 19, 13, 23,  7,  8, 18, 23, 19,\n",
       "          32, 21, 21, 32,  9,  4, 14, 11,  6,  7, 21,  5,  6, 32, 32, 32, 32, 32,\n",
       "          32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
       "          32, 32, 32, 32, 32, 32,  7,  4,  5, 22, 32, 19,  5,  5,  7, 12, 17,  6,\n",
       "          13, 10, 22, 18,  4, 17, 10, 18, 11, 11, 11,  4, 17, 13, 18, 17,  4,  7,\n",
       "           5, 20, 15, 19, 17, 32,  9, 14,  4, 11, 16, 32, 21,  7, 13, 12,  4,  6,\n",
       "          14,  4,  8,  5, 16, 32,  6, 12,  5,  7,  4, 13, 20, 23,  5,  8,  4, 32,\n",
       "           9,  4,  4, 16, 17,  6, 20, 17,  6, 10, 11, 12,  4,  6,  8,  5,  4,  4,\n",
       "           9, 13,  9, 18, 11, 14, 18, 13,  7,  7, 10, 16, 23,  8,  6, 32, 32, 18,\n",
       "          16,  2]]),\n",
       " 'ori_seq_t': tensor([[ 0,  8,  6, 18, 10, 15, 20,  5, 18, 14,  8,  6, 15,  7,  9,  6, 23, 20,\n",
       "           7, 16,  7, 11, 23,  6, 11, 11, 11,  4, 17,  6,  4, 22,  4, 13, 13,  7,\n",
       "           7, 19, 23, 14, 10, 21,  7, 12, 23, 11,  8,  9, 13, 20,  4, 17, 14, 17,\n",
       "          19,  9, 13,  4,  4, 12, 10, 15,  8, 17, 21, 17, 18,  4,  7, 16,  5,  6,\n",
       "          17,  7, 16,  4, 10,  7, 12,  6, 21,  8, 20, 16, 17, 23,  7,  4, 15,  4,\n",
       "          15,  7, 13, 11,  5, 17, 14, 15, 11, 14, 15, 19, 15, 18,  7, 10, 12, 16,\n",
       "          14,  6, 16, 11, 18,  8,  7,  4,  5, 23, 19, 17,  6,  8, 14,  8,  6,  7,\n",
       "          19, 16, 23,  5, 20, 10, 21, 17, 18, 11, 12, 15,  6,  8, 18,  4, 17,  6,\n",
       "           8, 23,  6,  8,  7,  6, 18, 17, 12, 13, 19, 13, 23,  7,  8, 18, 23, 19,\n",
       "          20, 21, 21, 20,  9,  4, 14, 11,  6,  7, 21,  5,  6, 11, 13,  4,  9,  6,\n",
       "          17, 18, 19,  6, 14, 18,  7, 13, 10, 16, 11,  5, 16,  5,  5,  6, 11, 13,\n",
       "          11, 11, 12, 11,  7, 17,  7,  4,  5, 22,  4, 19,  5,  5,  7, 12, 17,  6,\n",
       "          13, 10, 22, 18,  4, 17, 10, 18, 11, 11, 11,  4, 17, 13, 18, 17,  4,  7,\n",
       "           5, 20, 15, 19, 17, 19,  9, 14,  4, 11, 16, 13, 21,  7, 13, 12,  4,  6,\n",
       "          14,  4,  8,  5, 16, 11,  6, 12,  5,  7,  4, 13, 20, 23,  5,  8,  4, 15,\n",
       "           9,  4,  4, 16, 17,  6, 20, 17,  6, 10, 11, 12,  4,  6,  8,  5,  4,  4,\n",
       "           9, 13,  9, 18, 11, 14, 18, 13,  7,  7, 10, 16, 23,  8,  6,  7, 11, 18,\n",
       "          16,  2]]),\n",
       " 'prot': ['NSP5'],\n",
       " 'mask': tensor([[1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
       "          1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "          0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
       "          1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
       "          1., 1.]]),\n",
       " 'structure_t': None,\n",
       " 'ss8_t': None,\n",
       " 'sasa_t': None}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 308, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/core/module.py:447: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(134.9350, dtype=torch.float64, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae.training_step(j, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSSVLHSTQDLFLPFFSNVTWFHAIHVSGTNGTKRFDNPVLPFNDGVYFASTEKSNIIRGWIFGTTLDSKTQSLLIVNNATNVVIKVCEFQFCNDPFLGVYYHKNNKSWMESEFRVYSSANNCTFEYVSQPFLMDLEGKQGNFKNLREFVFKNIDGYFKIYSKHTPINLVRDLPQGFSALEPLVDLPIGINITRFQTLLALHRSYLTPGDSSSGWTAGAAAYYVGYLQPRTFLLKYNENGTITDAVDCALDPLSETKCTLKSFTVEKGIYQTSNFRVQPTESIVRFPNITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNFNFNGLTGTGVLTESNKKFLPFQQFGRDIADTTDAVRDPQTLEILDITPCSFGGVSVITPGTNTSNQVAVLYQDVNCTEVPVAIHADQLTPTWRVYSTGSNVFQTRAGCLIGAEHVNNSYECDIPIGAGICASYQTQTNSPRRARSVASQSIIAYTMSLGAENSVAYSNNSIAIPTNFTISVTTEILPVSMTKTSVDCTMYICGDSTECSNLLLQYGSFCTQLNRALTGIAVEQDKNTQEVFAQVKQIYKTPPIKDFGGFNFSQILPDPSKPSKRSFIEDLLFNKVTLADAGFIKQYGDCLGDIAARDLICAQKFNGLTVLPPLLTDEMIAQYTSALLAGTITSGWTFGAGAALQIPFAMQMAYRFNGIGVTQNVLYENQKLIANQFNSAIGKIQDSLSSTASALGKLQDVVNQNAQALNTLVKQLSSNFGAISSVLNDILSRLDKVEAEVQIDRLITGRLQSLQTYVTQQLIRAAEIRASANLAATKMSECVLGQSKRVDFCGKGYHLMSFPQSAPHGVVFLHVTYVPAQEKNFTTAPAICHDGKAHFPREGVFVSNGTHWFVTQRNFYEPQIITTDNTFVSGNCDVVIGIVNNTVYDPLQPELDSFKEELDKYFKNHTSPDVDLGDISGINASVVNIQKEIDRLNEVAKNLNESLIDLQELGKYEQYIKWPWYIWLGFIAGLIAIVMVTIMLCCMTSCCSCLKGCCSCGSCCKFDEDDSEPVLKGVKLHYT'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"/data/tyfei/datasets/Spike/standard.txt\")\n",
    "standard = f.readline().strip() \n",
    "f.close()\n",
    "standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein = ESMProtein(sequence=standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): UnifiedTransformerBlock(\n",
       "    (attn): MultiHeadAttention(\n",
       "      (layernorm_qkv): Sequential(\n",
       "        (0): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "      )\n",
       "      (out_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "      (q_ln): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (k_ln): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (rotary): RotaryEmbedding()\n",
       "    )\n",
       "    (geom_attn): GeometricReasoningOriginalImpl(\n",
       "      (s_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (proj): Linear(in_features=1536, out_features=3840, bias=False)\n",
       "      (out_proj): Linear(in_features=768, out_features=1536, bias=False)\n",
       "    )\n",
       "    (ffn): Sequential(\n",
       "      (0): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Linear(in_features=1536, out_features=8192, bias=False)\n",
       "      (2): SwiGLU()\n",
       "      (3): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (1-39): 39 x UnifiedTransformerBlock(\n",
       "    (attn): MultiHeadAttention(\n",
       "      (layernorm_qkv): Sequential(\n",
       "        (0): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "      )\n",
       "      (out_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "      (q_ln): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (k_ln): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (rotary): RotaryEmbedding()\n",
       "    )\n",
       "    (ffn): Sequential(\n",
       "      (0): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Linear(in_features=1536, out_features=8192, bias=False)\n",
       "      (2): SwiGLU()\n",
       "      (3): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (40-47): 8 x UnifiedTransformerBlock(\n",
       "    (attn): MultiHeadAttention(\n",
       "      (layernorm_qkv): Sequential(\n",
       "        (0): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): LinearWithLoRA(\n",
       "          (linear): Linear(in_features=1536, out_features=4608, bias=False)\n",
       "          (lora): LoRALayer()\n",
       "        )\n",
       "      )\n",
       "      (out_proj): LinearWithLoRA(\n",
       "        (linear): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "        (lora): LoRALayer()\n",
       "      )\n",
       "      (q_ln): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (k_ln): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (rotary): RotaryEmbedding()\n",
       "    )\n",
       "    (ffn): Sequential(\n",
       "      (0): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): LinearWithLoRA(\n",
       "        (linear): Linear(in_features=1536, out_features=8192, bias=False)\n",
       "        (lora): LoRALayer()\n",
       "      )\n",
       "      (2): SwiGLU()\n",
       "      (3): LinearWithLoRA(\n",
       "        (linear): Linear(in_features=4096, out_features=1536, bias=False)\n",
       "        (lora): LoRALayer()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cpu()\n",
    "res = model.encode(protein)\n",
    "# res.sequence[None, :]\n",
    "# res = model.forward(sequence_tokens=res.sequence[None, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 158.0931,  113.4213,  -16.8635,  ...,   13.8235,   11.9271,\n",
       "             8.1903],\n",
       "         [ 107.5984,   49.2519,  -42.7444,  ..., -217.9072,    7.2081,\n",
       "            26.4612],\n",
       "         [ 206.0871,   13.8621,  -37.0269,  ..., -158.8261,  -27.1618,\n",
       "            10.8131],\n",
       "         ...,\n",
       "         [ 118.6670,   15.5755, -115.0011,  ...,   47.9468,  253.2842,\n",
       "           170.3626],\n",
       "         [ 223.6516,  182.5809,    6.9576,  ...,   17.4236,  234.5673,\n",
       "           127.9122],\n",
       "         [  79.4623,  153.3872,  -67.3726,  ...,   20.7665,   99.0743,\n",
       "           165.0842]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = res.embeddings#.shape\n",
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "                                      \r"
     ]
    },
    {
     "ename": "InternalTorchDynamoError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n\nfrom user code:\n   File \"/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/esm/utils/structure/affine3d.py\", line 325, in _graham_schmidt\n    with fp32_autocast_context(x_axis.device.type):\n\nSet TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n\n\nYou can suppress this exception and fall back to eager by setting:\n    import torch._dynamo\n    torch._dynamo.config.suppress_errors = True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalTorchDynamoError\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m protein \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mprotein\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mGenerationConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msecondary_structure\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m protein \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m      6\u001b[0m     protein, GenerationConfig(track\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msasa\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m protein \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m      9\u001b[0m     protein, GenerationConfig(track\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstructure\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m     10\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/esm/models/esm3.py:382\u001b[0m, in \u001b[0;36mESM3.generate\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: ProteinType, config: GenerationConfig) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ProteinType:\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, ESMProtein):\n\u001b[0;32m--> 382\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterative_sampling_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, ESMProteinTensor):\n\u001b[1;32m    384\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m iterative_sampling_tokens(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizers)\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/esm/utils/generation.py:27\u001b[0m, in \u001b[0;36miterative_sampling_raw\u001b[0;34m(client, input, config)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miterative_sampling_raw\u001b[39m(\n\u001b[1;32m     20\u001b[0m     client: ESM3InferenceClient,\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28minput\u001b[39m: ESMProtein,\n\u001b[1;32m     22\u001b[0m     config: GenerationConfig,\n\u001b[1;32m     23\u001b[0m ):\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# Keep structure tokens\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     input_tokens \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m     output_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     raw_protein \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mdecode(output_tokens)\n\u001b[1;32m     31\u001b[0m     track_to_sample \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mtrack\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/esm/models/esm3.py:384\u001b[0m, in \u001b[0;36mESM3.generate\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m iterative_sampling_raw(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, config)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, ESMProteinTensor):\n\u001b[0;32m--> 384\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterative_sampling_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput must be an ESMProtein or ESMProteinTensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/esm/utils/generation.py:122\u001b[0m, in \u001b[0;36miterative_sampling_tokens\u001b[0;34m(client, input_tokens, config, tokenizers)\u001b[0m\n\u001b[1;32m    119\u001b[0m track_sample_config\u001b[38;5;241m.\u001b[39mtop_p \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mtop_p\n\u001b[1;32m    120\u001b[0m sampling_config \u001b[38;5;241m=\u001b[39m SamplingConfig(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{track_to_sample: track_sample_config})  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m forward_and_sample_output \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_and_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampled_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_config\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m new_samples \u001b[38;5;241m=\u001b[39m forward_and_sample_output\u001b[38;5;241m.\u001b[39mprotein_tensor\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# Calculate number of tokens to sample\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/esm/models/esm3.py:592\u001b[0m, in \u001b[0;36mESM3.forward_and_sample\u001b[0;34m(self, input, sampling_configuration)\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo input data provided\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m--> 592\u001b[0m forward_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprotein_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m    \u001b[49m\u001b[43mForwardConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mReturnLogitsConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m            \u001b[49m\u001b[43msequence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstructure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m            \u001b[49m\u001b[43msecondary_structure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m            \u001b[49m\u001b[43msasa\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresidue_annotations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;66;03m# Sampling\u001b[39;00m\n\u001b[1;32m    608\u001b[0m tokens_dir \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/esm/models/esm3.py:491\u001b[0m, in \u001b[0;36mESM3._forward\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m    488\u001b[0m     per_res_plddt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mcoordinates\u001b[38;5;241m.\u001b[39misfinite()\u001b[38;5;241m.\u001b[39mall(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39many(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext():\n\u001b[0;32m--> 491\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43msequence_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msequence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstructure_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mss8_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msecondary_structure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43msasa_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msasa\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunction_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresidue_annotation_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresidue_annotations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_plddt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mper_res_plddt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mper_res_plddt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstructure_coords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoordinates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchain_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43msequence_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mreturn_logits:\n\u001b[1;32m    506\u001b[0m         logits \u001b[38;5;241m=\u001b[39m ForwardTrackData(\n\u001b[1;32m    507\u001b[0m             sequence\u001b[38;5;241m=\u001b[39moutput\u001b[38;5;241m.\u001b[39msequence_logits,\n\u001b[1;32m    508\u001b[0m             structure\u001b[38;5;241m=\u001b[39moutput\u001b[38;5;241m.\u001b[39mstructure_logits,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m             function\u001b[38;5;241m=\u001b[39moutput\u001b[38;5;241m.\u001b[39mfunction_logits,\n\u001b[1;32m    512\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/esm/models/esm3.py:352\u001b[0m, in \u001b[0;36mESM3.forward\u001b[0;34m(self, sequence_tokens, structure_tokens, ss8_tokens, sasa_tokens, function_tokens, residue_annotation_tokens, average_plddt, per_res_plddt, structure_coords, chain_id, sequence_id)\u001b[0m\n\u001b[1;32m    345\u001b[0m     structure_coords \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull(\n\u001b[1;32m    346\u001b[0m         (\u001b[38;5;241m1\u001b[39m, L, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat, device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m    347\u001b[0m     )\n\u001b[1;32m    349\u001b[0m structure_coords \u001b[38;5;241m=\u001b[39m structure_coords[\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :\u001b[38;5;241m3\u001b[39m, :\n\u001b[1;32m    351\u001b[0m ]  \u001b[38;5;66;03m# In case we pass in an atom14 or atom37 repr\u001b[39;00m\n\u001b[0;32m--> 352\u001b[0m affine, affine_mask \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_affine3d_from_coordinates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstructure_coords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m structure_tokens \u001b[38;5;241m=\u001b[39m defaults(structure_tokens, C\u001b[38;5;241m.\u001b[39mSTRUCTURE_MASK_TOKEN)\n\u001b[1;32m    355\u001b[0m structure_tokens \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    356\u001b[0m     structure_tokens\u001b[38;5;241m.\u001b[39mmasked_fill(structure_tokens \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, C\u001b[38;5;241m.\u001b[39mSTRUCTURE_MASK_TOKEN)\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;241m.\u001b[39mmasked_fill(sequence_tokens \u001b[38;5;241m==\u001b[39m C\u001b[38;5;241m.\u001b[39mSEQUENCE_BOS_TOKEN, C\u001b[38;5;241m.\u001b[39mSTRUCTURE_BOS_TOKEN)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    363\u001b[0m     )\n\u001b[1;32m    364\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/esm/utils/structure/affine3d.py:363\u001b[0m, in \u001b[0;36mbuild_affine3d_from_coordinates\u001b[0;34m(coords)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;66;03m# NOTE(thayes): If you have already normalized the coordinates, then\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;66;03m# the black hole affine translations will be zeros and the rotations will be\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;66;03m# the identity.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m average_per_n_ca_c \u001b[38;5;241m=\u001b[39m coords\u001b[38;5;241m.\u001b[39mmasked_fill(\u001b[38;5;241m~\u001b[39mcoord_mask[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m], \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m (\n\u001b[1;32m    361\u001b[0m     coord_mask\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-8\u001b[39m\n\u001b[1;32m    362\u001b[0m )\n\u001b[0;32m--> 363\u001b[0m affine_from_average \u001b[38;5;241m=\u001b[39m \u001b[43matom3_to_backbone_affine\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43maverage_per_n_ca_c\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mas_matrix()\n\u001b[1;32m    367\u001b[0m B, S, _, _ \u001b[38;5;241m=\u001b[39m coords\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(B, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/esm/utils/structure/affine3d.py:352\u001b[0m, in \u001b[0;36mbuild_affine3d_from_coordinates.<locals>.atom3_to_backbone_affine\u001b[0;34m(bb_positions)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21matom3_to_backbone_affine\u001b[39m(bb_positions: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Affine3D:\n\u001b[1;32m    351\u001b[0m     N, CA, C \u001b[38;5;241m=\u001b[39m bb_positions\u001b[38;5;241m.\u001b[39munbind(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mAffine3D\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_graham_schmidt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/esm/utils/structure/affine3d.py:313\u001b[0m, in \u001b[0;36mAffine3D.from_graham_schmidt\u001b[0;34m(neg_x_axis, origin, xy_plane, eps)\u001b[0m\n\u001b[1;32m    310\u001b[0m x_axis \u001b[38;5;241m=\u001b[39m origin \u001b[38;5;241m-\u001b[39m neg_x_axis\n\u001b[1;32m    311\u001b[0m xy_plane \u001b[38;5;241m=\u001b[39m xy_plane \u001b[38;5;241m-\u001b[39m origin\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Affine3D(\n\u001b[0;32m--> 313\u001b[0m     trans\u001b[38;5;241m=\u001b[39morigin, rot\u001b[38;5;241m=\u001b[39m\u001b[43mRotationMatrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_graham_schmidt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxy_plane\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/esm/utils/structure/affine3d.py:158\u001b[0m, in \u001b[0;36mRotationMatrix.from_graham_schmidt\u001b[0;34m(x_axis, xy_plane, eps)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_graham_schmidt\u001b[39m(\n\u001b[1;32m    154\u001b[0m     x_axis: torch\u001b[38;5;241m.\u001b[39mTensor, xy_plane: torch\u001b[38;5;241m.\u001b[39mTensor, eps: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-12\u001b[39m\n\u001b[1;32m    155\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RotationMatrix:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# A low eps here is necessary for good stability!\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m RotationMatrix(\n\u001b[0;32m--> 158\u001b[0m         \u001b[43mmaybe_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_graham_schmidt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_axis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxy_plane\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:451\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m prior \u001b[38;5;241m=\u001b[39m set_eval_frame(callback)\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    453\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:921\u001b[0m, in \u001b[0;36mcatch_errors_wrapper.<locals>.catch_errors\u001b[0;34m(frame, cache_entry, frame_state)\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m hijacked_callback(frame, cache_entry, hooks, frame_state)\n\u001b[1;32m    919\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m compile_lock, _disable_current_modes():\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;66;03m# skip=1: skip this frame\u001b[39;00m\n\u001b[0;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:786\u001b[0m, in \u001b[0;36mconvert_frame.<locals>._convert_frame\u001b[0;34m(frame, cache_entry, hooks, frame_state, skip)\u001b[0m\n\u001b[1;32m    784\u001b[0m counters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframes\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 786\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43minner_convert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    789\u001b[0m     counters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframes\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mok\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:400\u001b[0m, in \u001b[0;36mconvert_frame_assert.<locals>._convert_frame_assert\u001b[0;34m(frame, cache_entry, hooks, frame_state, skip)\u001b[0m\n\u001b[1;32m    386\u001b[0m compile_id \u001b[38;5;241m=\u001b[39m CompileId(frame_id, frame_compile_id)\n\u001b[1;32m    388\u001b[0m signpost_event(\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdynamo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_convert_frame_assert._compile\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m     },\n\u001b[1;32m    398\u001b[0m )\n\u001b[0;32m--> 400\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_globals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_locals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_builtins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiler_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompile_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompile_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:703\u001b[0m, in \u001b[0;36m_compile\u001b[0;34m(code, globals, locals, builtins, compiler_fn, one_graph, export, export_constraints, hooks, cache_size, frame, frame_state, compile_id, skip)\u001b[0m\n\u001b[1;32m    701\u001b[0m         fail_user_frame_filename \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39minnermost_user_frame_summary\u001b[38;5;241m.\u001b[39mfilename  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    702\u001b[0m         fail_user_frame_lineno \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39minnermost_user_frame_summary\u001b[38;5;241m.\u001b[39mlineno  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InternalTorchDynamoError(\u001b[38;5;28mstr\u001b[39m(e))\u001b[38;5;241m.\u001b[39mwith_traceback(\n\u001b[1;32m    704\u001b[0m         e\u001b[38;5;241m.\u001b[39m__traceback__\n\u001b[1;32m    705\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tracer:\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:676\u001b[0m, in \u001b[0;36m_compile\u001b[0;34m(code, globals, locals, builtins, compiler_fn, one_graph, export, export_constraints, hooks, cache_size, frame, frame_state, compile_id, skip)\u001b[0m\n\u001b[1;32m    674\u001b[0m fail_user_frame_lineno: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 676\u001b[0m     guarded_code \u001b[38;5;241m=\u001b[39m \u001b[43mcompile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m guarded_code\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[1;32m    679\u001b[0m     Unsupported,\n\u001b[1;32m    680\u001b[0m     TorchRuntimeError,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    687\u001b[0m     BisectValidationException,\n\u001b[1;32m    688\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_dynamo/utils.py:262\u001b[0m, in \u001b[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (dynamo_timed)\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    261\u001b[0m     t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 262\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m     time_spent \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m    264\u001b[0m compilation_time_metrics[key]\u001b[38;5;241m.\u001b[39mappend(time_spent)\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:535\u001b[0m, in \u001b[0;36m_compile.<locals>.compile_inner\u001b[0;34m(code, one_graph, hooks, transform)\u001b[0m\n\u001b[1;32m    533\u001b[0m CompileContext\u001b[38;5;241m.\u001b[39mget()\u001b[38;5;241m.\u001b[39mattempt \u001b[38;5;241m=\u001b[39m attempt\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 535\u001b[0m     out_code \u001b[38;5;241m=\u001b[39m \u001b[43mtransform_code_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mRestartAnalysis \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py:1036\u001b[0m, in \u001b[0;36mtransform_code_object\u001b[0;34m(code, transformations, safe)\u001b[0m\n\u001b[1;32m   1033\u001b[0m instructions \u001b[38;5;241m=\u001b[39m cleaned_instructions(code, safe)\n\u001b[1;32m   1034\u001b[0m propagate_line_nums(instructions)\n\u001b[0;32m-> 1036\u001b[0m \u001b[43mtransformations\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m clean_and_assemble_instructions(instructions, keys, code_options)[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:165\u001b[0m, in \u001b[0;36mpreserve_global_state.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m cleanup \u001b[38;5;241m=\u001b[39m setup_compile_debug()\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m     cleanup\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:500\u001b[0m, in \u001b[0;36m_compile.<locals>.transform\u001b[0;34m(instructions, code_options)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tracing(tracer\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mtracing_context), tracer\u001b[38;5;241m.\u001b[39mset_current_tx():\n\u001b[0;32m--> 500\u001b[0m         \u001b[43mtracer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mUnspecializeRestartAnalysis:\n\u001b[1;32m    502\u001b[0m     speculation_log\u001b[38;5;241m.\u001b[39mclear()\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:2149\u001b[0m, in \u001b[0;36mInstructionTranslator.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 2149\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:810\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mpush_tx(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    807\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m (\n\u001b[1;32m    808\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstruction_pointer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mshould_exit\n\u001b[0;32m--> 810\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    811\u001b[0m     ):\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m BackendCompilerFailed:\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:773\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m         unimplemented(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmissing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minst\u001b[38;5;241m.\u001b[39mopname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    770\u001b[0m     TracingContext\u001b[38;5;241m.\u001b[39mset_current_loc(\n\u001b[1;32m    771\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_code\u001b[38;5;241m.\u001b[39mco_filename, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineno, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_code\u001b[38;5;241m.\u001b[39mco_name\n\u001b[1;32m    772\u001b[0m     )\n\u001b[0;32m--> 773\u001b[0m     \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inst\u001b[38;5;241m.\u001b[39mopname \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRETURN_VALUE\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported:\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:1311\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.LOAD_ATTR\u001b[0;34m(self, inst)\u001b[0m\n\u001b[1;32m   1309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mLOAD_ATTR\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst):\n\u001b[1;32m   1310\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpop()\n\u001b[0;32m-> 1311\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mBuiltinVariable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mConstantVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margval\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m   1313\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1314\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpush(result)\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_dynamo/variables/builtin.py:535\u001b[0m, in \u001b[0;36mBuiltinVariable.call_function\u001b[0;34m(self, tx, args, kwargs)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UserFunctionVariable\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wrap_fx_proxy, wrap_fx_proxy_cls\n\u001b[0;32m--> 535\u001b[0m args \u001b[38;5;241m=\u001b[39m [v\u001b[38;5;241m.\u001b[39mrealize() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[1;32m    536\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mrealize() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_dynamo/variables/builtin.py:535\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UserFunctionVariable\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wrap_fx_proxy, wrap_fx_proxy_cls\n\u001b[0;32m--> 535\u001b[0m args \u001b[38;5;241m=\u001b[39m [\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrealize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[1;32m    536\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mrealize() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_dynamo/variables/lazy.py:58\u001b[0m, in \u001b[0;36mLazyVariableTracker.realize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Force construction of the real VariableTracker\"\"\"\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mvt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrealize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparents_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mvt\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_dynamo/variables/lazy.py:24\u001b[0m, in \u001b[0;36mLazyCache.realize\u001b[0;34m(self, parents_tracker)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VariableBuilder\n\u001b[1;32m     23\u001b[0m tx \u001b[38;5;241m=\u001b[39m InstructionTranslator\u001b[38;5;241m.\u001b[39mcurrent_tx()\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvt \u001b[38;5;241m=\u001b[39m \u001b[43mVariableBuilder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvt\u001b[38;5;241m.\u001b[39mparents_tracker\u001b[38;5;241m.\u001b[39madd(parents_tracker)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_dynamo/variables/builder.py:269\u001b[0m, in \u001b[0;36mVariableBuilder.__call__\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstall_guards(dup_guard)\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m side_effect_result\n\u001b[0;32m--> 269\u001b[0m vt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m vt\u001b[38;5;241m.\u001b[39msource \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_lift_attrs_to_inputs(vt):\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_dynamo/variables/builder.py:402\u001b[0m, in \u001b[0;36mVariableBuilder._wrap\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    400\u001b[0m type_dispatch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_type_dispatch()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mtype\u001b[39m(value))\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m type_dispatch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtype_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;66;03m# Handle exact id() match\u001b[39;00m\n\u001b[1;32m    405\u001b[0m id_dispatch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id_dispatch()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mid\u001b[39m(value))\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_dynamo/variables/builder.py:1073\u001b[0m, in \u001b[0;36mVariableBuilder.wrap_tensor\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sparse_any(value):\n\u001b[1;32m   1069\u001b[0m     unimplemented(\n\u001b[1;32m   1070\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.compile does not support sparse Tensor with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;241m.\u001b[39mlayout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m layout\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1071\u001b[0m     )\n\u001b[0;32m-> 1073\u001b[0m tensor_variable \u001b[38;5;241m=\u001b[39m \u001b[43mwrap_fx_proxy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_proxy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexample_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubclass_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubclass_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstall_guards(\n\u001b[1;32m   1083\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[1;32m   1084\u001b[0m         GuardBuilder\u001b[38;5;241m.\u001b[39mTENSOR_MATCH,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1088\u001b[0m     )\n\u001b[1;32m   1089\u001b[0m )\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;66;03m# We install TYPE_MATCH guards for traceable wrapper subclass object,\u001b[39;00m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;66;03m# and recursively install corresponding guard for each inner attribute.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_dynamo/variables/builder.py:1330\u001b[0m, in \u001b[0;36mwrap_fx_proxy\u001b[0;34m(tx, proxy, example_value, subclass_type, **options)\u001b[0m\n\u001b[1;32m   1322\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtx\u001b[39m\u001b[38;5;124m\"\u001b[39m: tx,\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproxy\u001b[39m\u001b[38;5;124m\"\u001b[39m: proxy,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions,\n\u001b[1;32m   1328\u001b[0m }\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m subclass_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrap_fx_proxy_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTensorVariable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1332\u001b[0m     result \u001b[38;5;241m=\u001b[39m wrap_fx_proxy_cls(target_cls\u001b[38;5;241m=\u001b[39mTensorWithTFOverrideVariable, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_dynamo/variables/builder.py:1440\u001b[0m, in \u001b[0;36mwrap_fx_proxy_cls\u001b[0;34m(target_cls, tx, proxy, example_value, subclass_type, **options)\u001b[0m\n\u001b[1;32m   1438\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m options \u001b[38;5;129;01mand\u001b[39;00m options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1439\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m-> 1440\u001b[0m     example_value \u001b[38;5;241m=\u001b[39m \u001b[43mwrap_to_fake_tensor_and_record\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexample_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   1442\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(example_value, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m   1444\u001b[0m     maybe_get_fake_mode(example_value) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tx\u001b[38;5;241m.\u001b[39mfake_mode\n\u001b[1;32m   1445\u001b[0m ):\n\u001b[1;32m   1446\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InternalTorchDynamoError(\n\u001b[1;32m   1447\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`example_value` needs to be a `FakeTensor`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1448\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwrapped by this instance of Dynamo. Found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexample_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1449\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_dynamo/variables/builder.py:1880\u001b[0m, in \u001b[0;36mwrap_to_fake_tensor_and_record\u001b[0;34m(e, tx, source, is_tensor, parent_context)\u001b[0m\n\u001b[1;32m   1871\u001b[0m     symbolic_context \u001b[38;5;241m=\u001b[39m parent_context\u001b[38;5;241m.\u001b[39minner_contexts[inner_context_name]\n\u001b[1;32m   1873\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m   1874\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwrap_to_fake \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1875\u001b[0m     source\u001b[38;5;241m.\u001b[39mname(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28mtype\u001b[39m(e),\n\u001b[1;32m   1879\u001b[0m )\n\u001b[0;32m-> 1880\u001b[0m fake_e \u001b[38;5;241m=\u001b[39m \u001b[43mwrap_fake_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfake_mode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m        \u001b[49m\u001b[43msymbolic_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msymbolic_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_traceable_wrapper_subclass(fake_e):\n\u001b[1;32m   1889\u001b[0m     attrs, _ \u001b[38;5;241m=\u001b[39m fake_e\u001b[38;5;241m.\u001b[39m__tensor_flatten__()\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_dynamo/utils.py:1190\u001b[0m, in \u001b[0;36mwrap_fake_exception\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_fake_exception\u001b[39m(fn):\n\u001b[1;32m   1189\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1190\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m UnsupportedFakeTensorException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1192\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m unimplemented\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_dynamo/variables/builder.py:1881\u001b[0m, in \u001b[0;36mwrap_to_fake_tensor_and_record.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1871\u001b[0m     symbolic_context \u001b[38;5;241m=\u001b[39m parent_context\u001b[38;5;241m.\u001b[39minner_contexts[inner_context_name]\n\u001b[1;32m   1873\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m   1874\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwrap_to_fake \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1875\u001b[0m     source\u001b[38;5;241m.\u001b[39mname(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28mtype\u001b[39m(e),\n\u001b[1;32m   1879\u001b[0m )\n\u001b[1;32m   1880\u001b[0m fake_e \u001b[38;5;241m=\u001b[39m wrap_fake_exception(\n\u001b[0;32m-> 1881\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mtx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfake_mode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m        \u001b[49m\u001b[43msymbolic_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msymbolic_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1886\u001b[0m )\n\u001b[1;32m   1888\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_traceable_wrapper_subclass(fake_e):\n\u001b[1;32m   1889\u001b[0m     attrs, _ \u001b[38;5;241m=\u001b[39m fake_e\u001b[38;5;241m.\u001b[39m__tensor_flatten__()\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:1666\u001b[0m, in \u001b[0;36mFakeTensorMode.from_tensor\u001b[0;34m(self, tensor, static_shapes, source, symbolic_context, memoized_only)\u001b[0m\n\u001b[1;32m   1664\u001b[0m             symbolic_context \u001b[38;5;241m=\u001b[39m tracing_context\u001b[38;5;241m.\u001b[39mtensor_to_context[tensor]\n\u001b[1;32m   1665\u001b[0m             source \u001b[38;5;241m=\u001b[39m symbolic_context\u001b[38;5;241m.\u001b[39mtensor_source\n\u001b[0;32m-> 1666\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfake_tensor_converter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[43m    \u001b[49m\u001b[43msymbolic_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msymbolic_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemoized_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemoized_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1673\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:349\u001b[0m, in \u001b[0;36mFakeTensorConverter.__call__\u001b[0;34m(self, fake_mode, t, make_constant, shape_env, source, symbolic_context, memoized_only)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    340\u001b[0m     fake_mode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    347\u001b[0m     memoized_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    348\u001b[0m ):\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_real_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfake_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmake_constant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43msymbolic_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msymbolic_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemoized_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemoized_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:306\u001b[0m, in \u001b[0;36mFakeTensorConverter.from_real_tensor\u001b[0;34m(self, fake_mode, t, make_constant, shape_env, source, symbolic_context, memoized_only)\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m no_dispatch():\n\u001b[1;32m    299\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m FakeTensor(\n\u001b[1;32m    300\u001b[0m             fake_mode,\n\u001b[1;32m    301\u001b[0m             make_meta_t(),\n\u001b[1;32m    302\u001b[0m             existing_device,\n\u001b[1;32m    303\u001b[0m             constant\u001b[38;5;241m=\u001b[39mt \u001b[38;5;28;01mif\u001b[39;00m make_constant \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    304\u001b[0m         )\n\u001b[0;32m--> 306\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeta_converter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmk_fake_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43msymbolic_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msymbolic_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnsupportedFakeTensorException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta converter nyi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_subclasses/meta_utils.py:967\u001b[0m, in \u001b[0;36mMetaConverter.__call__\u001b[0;34m(self, t, shape_env, callback, source, symbolic_context)\u001b[0m\n\u001b[1;32m    965\u001b[0m disable_functorch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_DisableFuncTorch\n\u001b[1;32m    966\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m disable_functorch():\n\u001b[0;32m--> 967\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeta_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43msymbolic_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msymbolic_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(t) \u001b[38;5;129;01mis\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mParameter:\n\u001b[1;32m    975\u001b[0m     \u001b[38;5;66;03m# NB: Cannot directly use Parameter constructor\u001b[39;00m\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;66;03m# because that would force a detach, not desirable\u001b[39;00m\n\u001b[1;32m    977\u001b[0m     r\u001b[38;5;241m.\u001b[39m_is_param \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_subclasses/meta_utils.py:791\u001b[0m, in \u001b[0;36mMetaConverter.meta_tensor\u001b[0;34m(self, t, shape_env, callback, source, symbolic_context)\u001b[0m\n\u001b[1;32m    787\u001b[0m     r \u001b[38;5;241m=\u001b[39m empty_create_subclass(\n\u001b[1;32m    788\u001b[0m         t, outer_size\u001b[38;5;241m=\u001b[39msizes, outer_stride\u001b[38;5;241m=\u001b[39mstrides\n\u001b[1;32m    789\u001b[0m     )\n\u001b[1;32m    790\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 791\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_strided\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43msizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m safe_is_leaf(r), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe callback you passed in doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt detach\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mrequires_grad:\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:299\u001b[0m, in \u001b[0;36mFakeTensorConverter.from_real_tensor.<locals>.mk_fake_tensor\u001b[0;34m(make_meta_t)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmk_fake_tensor\u001b[39m(make_meta_t):\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;66;03m# NB: don't use in_kernel_invocation_manager. to\u001b[39;00m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;66;03m# ensure FakeTensor can internally do constant computation\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;66;03m# for which it is not strictly necessary to use the\u001b[39;00m\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;66;03m# invocation manager (I think!)\u001b[39;00m\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m no_dispatch():\n\u001b[0;32m--> 299\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFakeTensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfake_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmake_meta_t\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexisting_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconstant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmake_constant\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:487\u001b[0m, in \u001b[0;36mFakeTensor.__new__\u001b[0;34m(cls, fake_mode, elem, device, constant)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# normalize device.\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 487\u001b[0m     \u001b[43minit_cuda_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    490\u001b[0m     device\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_privateuse1_backend_name()]\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m device\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    493\u001b[0m ):\n\u001b[1;32m    494\u001b[0m     device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\n\u001b[1;32m    495\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mgetattr\u001b[39m(torch,\u001b[38;5;250m \u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype)\u001b[38;5;241m.\u001b[39mcurrent_device()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    496\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py:364\u001b[0m, in \u001b[0;36minit_cuda_context\u001b[0;34m()\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minit_cuda_context\u001b[39m():\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;66;03m# Backward will error with cuda Fake Tensors if no cuda tensors have been initialized first\u001b[39;00m\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m--> 364\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;241m.\u001b[39mhip \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[1;32m    365\u001b[0m             \u001b[38;5;241m1\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    366\u001b[0m         )\n",
      "\u001b[0;31mInternalTorchDynamoError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n\nfrom user code:\n   File \"/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/esm/utils/structure/affine3d.py\", line 325, in _graham_schmidt\n    with fp32_autocast_context(x_axis.device.type):\n\nSet TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n\n\nYou can suppress this exception and fall back to eager by setting:\n    import torch._dynamo\n    torch._dynamo.config.suppress_errors = True\n"
     ]
    }
   ],
   "source": [
    "protein = model.generate(\n",
    "                    protein,\n",
    "                    GenerationConfig(track=\"secondary_structure\", num_steps=16),\n",
    ")\n",
    "protein = model.generate(\n",
    "    protein, GenerationConfig(track=\"sasa\", num_steps=16)\n",
    ")\n",
    "protein = model.generate(\n",
    "    protein, GenerationConfig(track=\"structure\", num_steps=16)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.encode(protein)\n",
    "data = {}\n",
    "            \n",
    "data[\"seq_t\"] = res.sequence.cpu().numpy()\n",
    "data[\"structure_t\"] = res.structure.cpu().numpy()\n",
    "data[\"second_t\"] = res.secondary_structure.cpu().numpy()\n",
    "data[\"sasa_t\"] = res.sasa.cpu().numpy()\n",
    "# data[\"coordinates\"] = res.coordinates.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1275])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"seq_t\"][None, :].repeat(20, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 9.30 GiB. GPU \u0005 has a total capacity of 23.55 GiB of which 6.87 GiB is free. Including non-PyTorch memory, this process has 16.65 GiB memory in use. Of the allocated memory 11.61 GiB is allocated by PyTorch, and 4.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m representations \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m            \u001b[49m\u001b[43msequence_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq_t\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstructure_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstructure_t\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mss8_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msecond_t\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43msasa_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msasa_t\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m representations\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/esm/models/esm3.py:376\u001b[0m, in \u001b[0;36mESM3.forward\u001b[0;34m(self, sequence_tokens, structure_tokens, ss8_tokens, sasa_tokens, function_tokens, residue_annotation_tokens, average_plddt, per_res_plddt, structure_coords, chain_id, sequence_id)\u001b[0m\n\u001b[1;32m    355\u001b[0m structure_tokens \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    356\u001b[0m     structure_tokens\u001b[38;5;241m.\u001b[39mmasked_fill(structure_tokens \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, C\u001b[38;5;241m.\u001b[39mSTRUCTURE_MASK_TOKEN)\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;241m.\u001b[39mmasked_fill(sequence_tokens \u001b[38;5;241m==\u001b[39m C\u001b[38;5;241m.\u001b[39mSEQUENCE_BOS_TOKEN, C\u001b[38;5;241m.\u001b[39mSTRUCTURE_BOS_TOKEN)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    363\u001b[0m     )\n\u001b[1;32m    364\u001b[0m )\n\u001b[1;32m    366\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m    367\u001b[0m     sequence_tokens,\n\u001b[1;32m    368\u001b[0m     structure_tokens,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    374\u001b[0m     residue_annotation_tokens,\n\u001b[1;32m    375\u001b[0m )\n\u001b[0;32m--> 376\u001b[0m x, embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequence_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maffine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maffine_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchain_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_heads(x, embedding)\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/esm/layers/transformer_stack.py:93\u001b[0m, in \u001b[0;36mTransformerStack.forward\u001b[0;34m(self, x, sequence_id, affine, affine_mask, chain_id)\u001b[0m\n\u001b[1;32m     91\u001b[0m     chain_id \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(size\u001b[38;5;241m=\u001b[39mbatch_dims, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64, device\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m---> 93\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequence_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maffine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maffine_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchain_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x), x\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/esm/layers/blocks.py:147\u001b[0m, in \u001b[0;36mUnifiedTransformerBlock.forward\u001b[0;34m(self, x, sequence_id, frames, frames_mask, chain_id)\u001b[0m\n\u001b[1;32m    144\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m r1 \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaling_factor\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_geom_attn:\n\u001b[0;32m--> 147\u001b[0m     r2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeom_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequence_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchain_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m r2 \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaling_factor\n\u001b[1;32m    150\u001b[0m r3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn(x) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaling_factor\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/esm/layers/geom_attention.py:105\u001b[0m, in \u001b[0;36mGeometricReasoningOriginalImpl.forward\u001b[0;34m(self, s, affine, affine_mask, sequence_id, chain_id)\u001b[0m\n\u001b[1;32m    100\u001b[0m key_rot \u001b[38;5;241m=\u001b[39m rearrange(key_rot, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb s h d -> b h d s\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    101\u001b[0m value \u001b[38;5;241m=\u001b[39m rearrange(\n\u001b[1;32m    102\u001b[0m     value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb s (h m) d -> b h s (m d)\u001b[39m\u001b[38;5;124m\"\u001b[39m, m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_vector_messages\n\u001b[1;32m    103\u001b[0m )\n\u001b[0;32m--> 105\u001b[0m distance_term \u001b[38;5;241m=\u001b[39m (\u001b[43mquery_dist\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkey_dist\u001b[49m)\u001b[38;5;241m.\u001b[39mnorm(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m sqrt(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    106\u001b[0m rotation_term \u001b[38;5;241m=\u001b[39m query_rot\u001b[38;5;241m.\u001b[39mmatmul(key_rot) \u001b[38;5;241m/\u001b[39m sqrt(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    107\u001b[0m distance_term_weight \u001b[38;5;241m=\u001b[39m rearrange(\n\u001b[1;32m    108\u001b[0m     F\u001b[38;5;241m.\u001b[39msoftplus(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistance_scale_per_head), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh -> h 1 1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    109\u001b[0m )\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 9.30 GiB. GPU \u0005 has a total capacity of 23.55 GiB of which 6.87 GiB is free. Including non-PyTorch memory, this process has 16.65 GiB memory in use. Of the allocated memory 11.61 GiB is allocated by PyTorch, and 4.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "representations = model(\n",
    "            sequence_tokens=data[\"seq_t\"][None, :].repeat(2, 1),\n",
    "            structure_tokens=data[\"structure_t\"][None, :].repeat(2, 1),\n",
    "            ss8_tokens=data[\"second_t\"][None, :].repeat(2, 1),\n",
    "            sasa_tokens=data[\"sasa_t\"][None, :].repeat(2, 1),\n",
    "        )\n",
    "representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seq_t': array([ 0, 20, 18, ..., 19, 11,  2]),\n",
       " 'structure_t': array([4098,  247, 3611, ...,  808,  124, 4097]),\n",
       " 'second_t': array([ 0, 10, 10, ..., 10, 10,  0]),\n",
       " 'sasa_t': array([ 0, 18, 18, ..., 18, 18,  0]),\n",
       " 'coordinates': array([[[         inf,          inf,          inf],\n",
       "         [         inf,          inf,          inf],\n",
       "         [         inf,          inf,          inf],\n",
       "         ...,\n",
       "         [         inf,          inf,          inf],\n",
       "         [         inf,          inf,          inf],\n",
       "         [         inf,          inf,          inf]],\n",
       " \n",
       "        [[ 61.731552  ,  -6.571238  ,  16.325504  ],\n",
       "         [ 62.342125  ,  -7.4330754 ,  15.318746  ],\n",
       "         [ 61.35109   ,  -8.477322  ,  14.815431  ],\n",
       "         ...,\n",
       "         [         inf,          inf,          inf],\n",
       "         [         inf,          inf,          inf],\n",
       "         [         inf,          inf,          inf]],\n",
       " \n",
       "        [[ 61.160416  ,  -8.275962  ,  15.921618  ],\n",
       "         [ 61.024757  ,  -9.643171  ,  15.430236  ],\n",
       "         [ 59.80917   ,  -9.781591  ,  14.519675  ],\n",
       "         ...,\n",
       "         [         inf,          inf,          inf],\n",
       "         [         inf,          inf,          inf],\n",
       "         [         inf,          inf,          inf]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-25.268896  ,   2.7087035 , -27.905983  ],\n",
       "         [-25.852705  ,   1.9997438 , -29.039856  ],\n",
       "         [-25.914371  ,   0.49880445, -28.776588  ],\n",
       "         ...,\n",
       "         [         inf,          inf,          inf],\n",
       "         [         inf,          inf,          inf],\n",
       "         [         inf,          inf,          inf]],\n",
       " \n",
       "        [[-25.941496  ,   1.0694984 , -28.256039  ],\n",
       "         [-26.060972  ,  -0.37128413, -28.453506  ],\n",
       "         [-25.786287  ,  -1.127956  , -27.158161  ],\n",
       "         ...,\n",
       "         [         inf,          inf,          inf],\n",
       "         [         inf,          inf,          inf],\n",
       "         [         inf,          inf,          inf]],\n",
       " \n",
       "        [[         inf,          inf,          inf],\n",
       "         [         inf,          inf,          inf],\n",
       "         [         inf,          inf,          inf],\n",
       "         ...,\n",
       "         [         inf,          inf,          inf],\n",
       "         [         inf,          inf,          inf],\n",
       "         [         inf,          inf,          inf]]], dtype=float32)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esm3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
