{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d0145f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import modules\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caabb289",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy_mutation = nn.CrossEntropyLoss(\n",
    "            weight=torch.tensor([0.1, 1.0, 1.0])\n",
    "        )\n",
    "t1 = torch.randn((1200, 3))\n",
    "q = torch.randint(0, 3, (1200,))\n",
    "loss = cross_entropy_mutation(t1, q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3f9546",
   "metadata": {},
   "source": [
    "### test loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55bd25dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import trainUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cb0d88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build finetune model\n",
      "model at stage: training stage 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    }
   ],
   "source": [
    "path = \"/data2/tyfei/trainresults/evomodel/train_siqi\" \n",
    "with open(os.path.join(path, \"config.json\"), \"r\") as f:\n",
    "    configs = json.load(f)\n",
    "ds = trainUtils.loadDataset(configs)\n",
    "pretrain_model = trainUtils.loadPretrainModel(configs)\n",
    "print(\"build finetune model\")\n",
    "model = trainUtils.buildModel(configs, pretrain_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be8ad6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 20 18 ... 19 11  2]\n",
      "[ 0 20 18 ... 19 11  2]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m129\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/evoModel/modules.py:791\u001b[0m, in \u001b[0;36mVESM.training_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    789\u001b[0m     input_dict1 \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m    790\u001b[0m     input_dict2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 791\u001b[0m loss, d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_common_training_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dict1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dict2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    792\u001b[0m dp \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    793\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m d:\n",
      "File \u001b[0;32m~/evoModel/modules.py:728\u001b[0m, in \u001b[0;36mVESM._common_training_step\u001b[0;34m(self, input_dict1, input_dict2)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_common_training_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_dict1, input_dict2\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 728\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dict1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dict2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining stage 1\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpretraining stage 1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    731\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(loss\u001b[38;5;241m.\u001b[39mS1PredictsLosses) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/evoModel/modules.py:618\u001b[0m, in \u001b[0;36mVESM.getLoss\u001b[0;34m(self, input_dict1, input_dict2)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetLoss\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_dict1, input_dict2\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 618\u001b[0m     output1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_dict1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_dict1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstage_1_masks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_dict1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstage_2_masks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m input_dict2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    624\u001b[0m         output2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\n\u001b[1;32m    625\u001b[0m             input_dict2[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    626\u001b[0m             input_dict2\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage_1_masks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    627\u001b[0m             input_dict2\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage_2_masks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    628\u001b[0m         )\n",
      "File \u001b[0;32m~/evoModel/modules.py:463\u001b[0m, in \u001b[0;36mVESM.forward\u001b[0;34m(self, input_dict, stage_1_masks, stage_2_masks, only_stage_1)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28mself\u001b[39m, input_dict, stage_1_masks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, stage_2_masks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, only_stage_1\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    461\u001b[0m ):\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage 1\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage:\n\u001b[0;32m--> 463\u001b[0m         stage_1_embeds, stage_1_logits, stage_1_predicts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstage1_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage_1_masks\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining stage 1\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpretraining stage 1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    467\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m VESMOutputs(\n\u001b[1;32m    468\u001b[0m                 S1Embeddings\u001b[38;5;241m=\u001b[39mstage_1_embeds,\n\u001b[1;32m    469\u001b[0m                 S1Logits\u001b[38;5;241m=\u001b[39mstage_1_logits,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m                 S2Predicts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    474\u001b[0m             )\n",
      "File \u001b[0;32m~/evoModel/modules.py:383\u001b[0m, in \u001b[0;36mVESM.stage1_forward\u001b[0;34m(self, input_dict, masks)\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28mprint\u001b[39m(input_dict[i])\n\u001b[0;32m--> 383\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mesm_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m embed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage_1_bottleneck(x)\n\u001b[1;32m    385\u001b[0m batchsize, length, channels \u001b[38;5;241m=\u001b[39m embed\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/evoModel/modules.py:937\u001b[0m, in \u001b[0;36mESMModule.forward\u001b[0;34m(self, input_dict)\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28mprint\u001b[39m(input_dict)\n\u001b[1;32m    936\u001b[0m t \u001b[38;5;241m=\u001b[39m input_dict\n\u001b[0;32m--> 937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    938\u001b[0m     t \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    940\u001b[0m representations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mesm_model(\n\u001b[1;32m    941\u001b[0m     sequence_tokens\u001b[38;5;241m=\u001b[39mt,\n\u001b[1;32m    942\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "model.training_step(list(d[129]), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aa96977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get train loader\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'input': {'Spike': array([ 0, 20, 18, ..., 19, 11,  2]),\n",
       "   'aligned_Spike': array([ 0, 20, 18, ..., 19, 11,  2])},\n",
       "  'ori_seq': {'Spike': array([ 0, 20, 18, ..., 19, 11,  2])},\n",
       "  'stage_1_masks': {'Spike': array([1, 1, 1, ..., 1, 1, 1], dtype=int32)},\n",
       "  'label': {'Spike': []},\n",
       "  'mutation_label': {'Spike': tensor([0, 0, 0,  ..., 0, 0, 0])},\n",
       "  'meta': {'id': 'OEAV22454769', 'bin': '1610', 'days': 1615}},\n",
       " {'input': {'Spike': array([ 0, 20, 18, ..., 19, 11,  2]),\n",
       "   'aligned_Spike': array([ 0, 20, 18, ..., 19, 11,  2])},\n",
       "  'ori_seq': {'Spike': array([ 0, 20, 18, ..., 19, 11,  2])},\n",
       "  'stage_1_masks': {'Spike': array([1, 1, 1, ..., 1, 1, 1], dtype=int32)},\n",
       "  'label': {'Spike': []},\n",
       "  'mutation_label': {'Spike': tensor([0, 0, 0,  ..., 0, 0, 0])},\n",
       "  'meta': {'id': 'OEAV22474316', 'bin': '1631', 'days': 1636}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = ds.train_dataloader()\n",
    "d = d.dataset\n",
    "d[129]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "041a89c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Spike': array([ 0, 20, 18, ..., 19, 11,  2]),\n",
       " 'aligned_Spike': array([ 0, 20, 18, ..., 19, 11,  2])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[129][0][\"input\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcb07f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 20, 18, ..., 19, 11,  2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"/data/tyfei/datasets/covid/ori_seq3.pkl\", \"rb\") as f:\n",
    "    d = pickle.load(f)\n",
    "spike = d[\"Spike\"]\n",
    "spike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ba41618",
   "metadata": {},
   "outputs": [],
   "source": [
    "class testModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(30, 100) \n",
    "        self.decoder = modules.DecoderBlock(100, 5, 30, 3) \n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69d3b8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.7031874656677246\n",
      "10 0.11883002519607544\n",
      "20 0.0011939909309148788\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m loss \u001b[38;5;241m=\u001b[39m cri(out\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m33\u001b[39m), torch\u001b[38;5;241m.\u001b[39mtensor(spike)\u001b[38;5;241m.\u001b[39mlong())\n\u001b[1;32m      8\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 9\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = modules.DecoderBlock(1024, 16, 33, 5) \n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "cri = nn.CrossEntropyLoss() \n",
    "for i in range(100):\n",
    "    x = torch.ones((1, 1275, 1024)).float()\n",
    "    out = model(x)\n",
    "    loss = cri(out.view(-1, 33), torch.tensor(spike).long())\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    if i % 10 == 0:\n",
    "        print(i, loss.item())\n",
    "        # print(out.shape, spike.shape)\n",
    "        # print(out[0, 0, :10], spike[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4338b29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 20, 18,  ..., 19, 11,  2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones((1, 1275, 1024)).float()\n",
    "out = model(x)\n",
    "out = out.squeeze(0)\n",
    "out = out.argmax(dim=-1)     \n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "119de7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Loss: 3.5705902576446533\n",
      "Step 20, Loss: 2.9788079261779785\n",
      "Step 40, Loss: 2.4528794288635254\n",
      "Step 60, Loss: 1.0887776613235474\n",
      "Step 80, Loss: 0.01829402893781662\n",
      "Step 100, Loss: 0.003664557356387377\n",
      "Step 120, Loss: 0.0020231674425303936\n",
      "Step 140, Loss: 0.0016921693459153175\n",
      "Step 160, Loss: 0.0012823834549635649\n",
      "Step 180, Loss: 0.0011464199051260948\n"
     ]
    }
   ],
   "source": [
    "model = testModule()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "cri = nn.CrossEntropyLoss()\n",
    "for i in range(200):\n",
    "    x = torch.randint(1, 30, (32, 10))\n",
    "    x[:, -1] = 0\n",
    "    y = x.clone()\n",
    "    y[:, 1:] = x[:, :-1]\n",
    "    y[:, 0] = 0  # Set the first token to a specific value (e.g., 0)\n",
    "    optim.zero_grad()\n",
    "    out = model(x)\n",
    "    loss = cri(out.view(-1, 30), y.view(-1))\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    if i % 20 == 0:\n",
    "        print(f\"Step {i}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10717849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcf9740",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esm3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
